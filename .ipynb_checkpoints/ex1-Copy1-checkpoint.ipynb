{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from submit import submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156060\n",
      "Index([u'PhraseId', u'SentenceId', u'Phrase', u'Sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "training_df = pd.read_csv(\"train.tsv\", error_bad_lines=False , sep='\\t')\n",
    "# training_df.columns = ['textID', '']\n",
    "print len(training_df)\n",
    "print training_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "0     7072\n",
      "1    27273\n",
      "2    79582\n",
      "3    32927\n",
      "4     9206\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print training_df.groupby(['Sentiment']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data_alittle(text):\n",
    "    return [re.sub('_|#|:|\\n|,|;|«|»|!|-|%|$|@|<|>|\\.|\\...',' ',t) for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_temp, testing_temp = train_test_split(shuffle(training_df), train_size=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = prepare_data_alittle(training_temp['Phrase'].tolist())\n",
    "X_test = prepare_data_alittle(testing_temp['Phrase'].tolist())\n",
    "Y_train = training_temp['Sentiment'].tolist()\n",
    "Y_test = testing_temp['Sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([('vect', CountVectorizer()), ('clf', LinearSVC())])\n",
    "# pipeline = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', SVC())])\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), stop_words = list(set(stopwords.words(\"english\")) ))),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "#     'vect__max_df': (.7, .8, .85, .9, 1), \n",
    "#                 'vect__min_df': (.1, .15, .2, 1),\n",
    "#                 'vect__max_features': (None, 5000, 10000, 20000),\n",
    "#                 'vect__ngram_range': ((1, 1), (1, 2), (1,3)),\n",
    "#                 'tfidf__use_idf': (True, False),\n",
    "#                 'tfidf__norm': ('l1', 'l2'),\n",
    "                'clf__gamma': (0.001, 0.0001, 10),\n",
    "                'clf__C': (.1, 1, 5),\n",
    "                'clf__class_weight': (None, 'balanced'),\n",
    "                'clf__kernel': (\"linear\", \"rbf\")}\n",
    "# p_parameters = {#'vect__max_df': (.85, .75), \n",
    "# #                 'vect__min_df': (.15, 1),\n",
    "# #                 'vect__max_features': (None, 10000),\n",
    "#                 'vect__ngram_range': ((1, 1)),\n",
    "#                 'tfidf__use_idf': (True, False),\n",
    "# #                 'tfidf__norm': ('l1', 'l2'),\n",
    "# #                 'clf__gamma': (0.001, 10, 100),\n",
    "# #                 'clf__C': (.1, .5, 1),\n",
    "# #                 'clf__degree': (1, 2, 3),\n",
    "# #                 'clf__class_weight': (None, 'balanced'),\n",
    "#                 'clf__kernel': (\"linear\", \"rbf\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 154 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 342.7min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed: 1105.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56min 58s, sys: 23.4 s, total: 57min 21s\n",
      "Wall time: 19h 19min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None,\n",
       "        stop_words=[u'all',...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__gamma': (0.001, 0.0001, 10), 'clf__C': (0.1, 1, 5), 'clf__class_weight': (None, 'balanced'), 'clf__kernel': ('linear', 'rbf')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_search.fit(X_train, Y_train)\n",
    "# best_parameters = grid_search.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__C: 1\n",
      "\tclf__class_weight: None\n",
      "\tclf__gamma: 0.001\n",
      "\tclf__kernel: 'linear'\n"
     ]
    }
   ],
   "source": [
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countVec = CountVectorizer(ngram_range=(1,3), stop_words = list(set(stopwords.words(\"english\")) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_features = countVec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 43.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = SGDClassifier()#svm.LinearSVC(C = .1, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.66 s, sys: 16 ms, total: 1.67 s\n",
      "Wall time: 434 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = model.fit(tr_features, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te_features = countVec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvm_r = model.predict(te_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         negative       0.63      0.05      0.09      2164\n",
      "somewhat negative       0.43      0.03      0.06      8219\n",
      "          neutral       0.53      0.98      0.69     23739\n",
      "somewhat positive       0.56      0.10      0.18      9931\n",
      "         positive       0.65      0.10      0.17      2765\n",
      "\n",
      "      avg / total       0.53      0.53      0.41     46818\n",
      "\n",
      "accuracy :  0.531761288393\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(Y_test, lsvm_r.tolist(), target_names=[\"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"])\n",
    "print(report)\n",
    "\n",
    "\n",
    "print 'accuracy : ' , accuracy_score(Y_test, lsvm_r.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         negative       0.63      0.05      0.09      2164\n",
      "somewhat negative       0.43      0.03      0.06      8219\n",
      "          neutral       0.53      0.98      0.69     23739\n",
      "somewhat positive       0.56      0.10      0.18      9931\n",
      "         positive       0.65      0.10      0.17      2765\n",
      "\n",
      "      avg / total       0.53      0.53      0.41     46818\n",
      "\n",
      "accuracy :  0.531761288393\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(Y_test, lsvm_r.tolist(), target_names=[\"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"])\n",
    "print(report)\n",
    "\n",
    "\n",
    "print 'accuracy : ' , accuracy_score(Y_test, lsvm_r.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-1d08906618ca>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-1d08906618ca>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    precision    recall  f1-score   support\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "                   precision    recall  f1-score   support\n",
    "\n",
    "         negative       0.42      0.48      0.45      2132\n",
    "somewhat negative       0.53      0.51      0.52      8287\n",
    "          neutral       0.75      0.76      0.75     23814\n",
    "somewhat positive       0.55      0.51      0.53      9808\n",
    "         positive       0.44      0.49      0.46      2777\n",
    "\n",
    "      avg / total       0.63      0.63      0.63     46818\n",
    "\n",
    "accuracy :  0.633666538511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named dill",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b3020b006e67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named dill"
     ]
    }
   ],
   "source": [
    "import dill"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
